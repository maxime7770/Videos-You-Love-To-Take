{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "\n",
    "# Run imports\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tqdm\n",
    "import absl.logging\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "mpl.rcParams.update({\n",
    "    'font.size': 10,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_and_sum_labels_and_probs(outputs, label_mapping):\n",
    "    new_outputs = {}\n",
    "    for label, prob in outputs:\n",
    "        if label in label_mapping:\n",
    "            new_label = label_mapping[label]\n",
    "            if new_label in new_outputs:\n",
    "                new_outputs[new_label] += prob\n",
    "            else:\n",
    "                new_outputs[new_label] = prob\n",
    "        else:\n",
    "            if label in new_outputs:\n",
    "                new_outputs[label] += prob\n",
    "            else:\n",
    "                new_outputs[label] = prob\n",
    "\n",
    "    return list(new_outputs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code mostly from https://github.com/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb\n",
    "\n",
    "# Download Kinetics 600 label map\n",
    "!wget https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt -O labels.txt -q\n",
    "\n",
    "with tf.io.gfile.GFile('labels.txt') as f:\n",
    "  lines = f.readlines()\n",
    "  KINETICS_600_LABELS_LIST = [line.strip() for line in lines]\n",
    "  KINETICS_600_LABELS = tf.constant(KINETICS_600_LABELS_LIST)\n",
    "\n",
    "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
    "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
    "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
    "  return tuple(zip(top_labels, top_probs))\n",
    "\n",
    "def predict_top_k(model, video, k=5, label_map=KINETICS_600_LABELS):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
    "  outputs = model.predict(video[tf.newaxis])[0]\n",
    "  probs = tf.nn.softmax(outputs)\n",
    "  return get_top_k(probs, k=k, label_map=label_map)\n",
    "\n",
    "def load_movinet_from_hub(model_id, model_mode, hub_version=3):\n",
    "  \"\"\"Loads a MoViNet model from TF Hub.\"\"\"\n",
    "  hub_url = f'https://tfhub.dev/tensorflow/movinet/{model_id}/{model_mode}/kinetics-600/classification/{hub_version}'\n",
    "\n",
    "  encoder = hub.KerasLayer(hub_url, trainable=True)\n",
    "\n",
    "  inputs = tf.keras.layers.Input(\n",
    "      shape=[None, None, None, 3],\n",
    "      dtype=tf.float32)\n",
    "\n",
    "  if model_mode == 'base':\n",
    "    inputs = dict(image=inputs)\n",
    "  else:\n",
    "    # Define the state inputs, which is a dict that maps state names to tensors.\n",
    "    init_states_fn = encoder.resolved_object.signatures['init_states']\n",
    "    state_shapes = {\n",
    "        name: ([s if s > 0 else None for s in state.shape], state.dtype)\n",
    "        for name, state in init_states_fn(tf.constant([0, 0, 0, 0, 3])).items()\n",
    "    }\n",
    "    states_input = {\n",
    "        name: tf.keras.Input(shape[1:], dtype=dtype, name=name)\n",
    "        for name, (shape, dtype) in state_shapes.items()\n",
    "    }\n",
    "\n",
    "    # The inputs to the model are the states and the video\n",
    "    inputs = {**states_input, 'image': inputs}\n",
    "\n",
    "  # Output shape: [batch_size, 600]\n",
    "  outputs = encoder(inputs)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  model.build([1, 1, 1, 1, 3])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Download example gif\n",
    "!wget https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif -O jumpingjack.gif -q\n",
    "\n",
    "def load_gif(file_path, image_size=(224, 224)):\n",
    "  \"\"\"Loads an mp4 file into a TF tensor.\"\"\"\n",
    "  cap = cv2.VideoCapture(file_path)\n",
    "    \n",
    "  frames = []\n",
    "  while True:\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "      frame = cv2.resize(frame, image_size)\n",
    "      frames.append(frame)\n",
    "\n",
    "  cap.release()\n",
    "  \n",
    "  video = tf.convert_to_tensor(frames, dtype=tf.float32) / 255.0\n",
    "  return video\n",
    "\n",
    "def get_top_k_streaming_labels(probs, k=5, label_map=KINETICS_600_LABELS_LIST):\n",
    "  \"\"\"Returns the top-k labels over an entire video sequence.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    k: the number of top predictions to select.\n",
    "    label_map: a list of labels to map logit indices to label strings.\n",
    "\n",
    "  Returns:\n",
    "    a tuple of the top-k probabilities, labels, and logit indices\n",
    "  \"\"\"\n",
    "  top_categories_last = tf.argsort(probs, -1, 'DESCENDING')[-1, :1]\n",
    "  categories = tf.argsort(probs, -1, 'DESCENDING')[:, :k]\n",
    "  categories = tf.reshape(categories, [-1])\n",
    "\n",
    "  counts = sorted([\n",
    "      (i.numpy(), tf.reduce_sum(tf.cast(categories == i, tf.int32)).numpy())\n",
    "      for i in tf.unique(categories)[0]\n",
    "  ], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  top_probs_idx = tf.constant([i for i, _ in counts[:k]])\n",
    "  top_probs_idx = tf.concat([top_categories_last, top_probs_idx], 0)\n",
    "  top_probs_idx = tf.unique(top_probs_idx)[0][:k+1]\n",
    "\n",
    "  top_probs = tf.gather(probs, top_probs_idx, axis=-1)\n",
    "  top_probs = tf.transpose(top_probs, perm=(1, 0))\n",
    "  top_labels = tf.gather(label_map, top_probs_idx, axis=0)\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "\n",
    "  return top_probs, top_labels, top_probs_idx\n",
    "\n",
    "def plot_streaming_top_preds_at_step(\n",
    "    top_probs,\n",
    "    top_labels,\n",
    "    step=None,\n",
    "    image=None,\n",
    "    legend_loc='lower left',\n",
    "    duration_seconds=10,\n",
    "    figure_height=500,\n",
    "    playhead_scale=0.8,\n",
    "    grid_alpha=0.3):\n",
    "  \"\"\"Generates a plot of the top video model predictions at a given time step.\n",
    "\n",
    "  Args:\n",
    "    top_probs: a tensor of shape (k, num_frames) representing the top-k\n",
    "      probabilities over all frames.\n",
    "    top_labels: a list of length k that represents the top-k label strings.\n",
    "    step: the current time step in the range [0, num_frames].\n",
    "    image: the image frame to display at the current time step.\n",
    "    legend_loc: the placement location of the legend.\n",
    "    duration_seconds: the total duration of the video.\n",
    "    figure_height: the output figure height.\n",
    "    playhead_scale: scale value for the playhead.\n",
    "    grid_alpha: alpha value for the gridlines.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the output numpy image, figure, and axes.\n",
    "  \"\"\"\n",
    "  num_labels, num_frames = top_probs.shape\n",
    "  if step is None:\n",
    "    step = num_frames\n",
    "\n",
    "  fig = plt.figure(figsize=(6.5, 7), dpi=300)\n",
    "  gs = mpl.gridspec.GridSpec(8, 1)\n",
    "  ax2 = plt.subplot(gs[:-3, :])\n",
    "  ax = plt.subplot(gs[-3:, :])\n",
    "\n",
    "  if image is not None:\n",
    "    ax2.imshow(image, interpolation='nearest')\n",
    "    ax2.axis('off')\n",
    "\n",
    "  preview_line_x = tf.linspace(0., duration_seconds, num_frames)\n",
    "  preview_line_y = top_probs\n",
    "\n",
    "  line_x = preview_line_x[:step+1]\n",
    "  line_y = preview_line_y[:, :step+1]\n",
    "\n",
    "  for i in range(num_labels):\n",
    "    ax.plot(preview_line_x, preview_line_y[i], label=None, linewidth='1.5',\n",
    "            linestyle=':', color='gray')\n",
    "    ax.plot(line_x, line_y[i], label=top_labels[i], linewidth='2.0')\n",
    "\n",
    "\n",
    "  ax.grid(which='major', linestyle=':', linewidth='1.0', alpha=grid_alpha)\n",
    "  ax.grid(which='minor', linestyle=':', linewidth='0.5', alpha=grid_alpha)\n",
    "\n",
    "  min_height = tf.reduce_min(top_probs) * playhead_scale\n",
    "  max_height = tf.reduce_max(top_probs)\n",
    "  ax.vlines(preview_line_x[step], min_height, max_height, colors='red')\n",
    "  ax.scatter(preview_line_x[step], max_height, color='red')\n",
    "\n",
    "  ax.legend(loc=legend_loc)\n",
    "\n",
    "  plt.xlim(0, duration_seconds)\n",
    "  plt.ylabel('Probability')\n",
    "  plt.xlabel('Time (s)')\n",
    "  plt.yscale('log')\n",
    "\n",
    "  fig.tight_layout()\n",
    "  fig.canvas.draw()\n",
    "\n",
    "  data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "  data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "  plt.close()\n",
    "\n",
    "  figure_width = int(figure_height * data.shape[1] / data.shape[0])\n",
    "  image = PIL.Image.fromarray(data).resize([figure_width, figure_height])\n",
    "  image = np.array(image)\n",
    "\n",
    "  return image, (fig, ax, ax2)\n",
    "\n",
    "def plot_streaming_top_preds(\n",
    "    probs,\n",
    "    video,\n",
    "    top_k=5,\n",
    "    video_fps=25.,\n",
    "    figure_height=500,\n",
    "    use_progbar=True):\n",
    "  \"\"\"Generates a video plot of the top video model predictions.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    video: the video to display in the plot.\n",
    "    top_k: the number of top predictions to select.\n",
    "    video_fps: the input video fps.\n",
    "    figure_fps: the output video fps.\n",
    "    figure_height: the height of the output video.\n",
    "    use_progbar: display a progress bar.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array representing the output video.\n",
    "  \"\"\"\n",
    "  video_fps = 8.\n",
    "  figure_height = 500\n",
    "  steps = video.shape[0]\n",
    "  duration = steps / video_fps\n",
    "\n",
    "  top_probs, top_labels, _ = get_top_k_streaming_labels(probs, k=top_k)\n",
    "\n",
    "  images = []\n",
    "  step_generator = tqdm.trange(steps) if use_progbar else range(steps)\n",
    "  for i in step_generator:\n",
    "    image, _ = plot_streaming_top_preds_at_step(\n",
    "        top_probs=top_probs,\n",
    "        top_labels=top_labels,\n",
    "        step=i,\n",
    "        image=video[i],\n",
    "        duration_seconds=duration,\n",
    "        figure_height=figure_height,\n",
    "    )\n",
    "    images.append(image)\n",
    "\n",
    "  return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_movinet_from_hub('a2', 'base', hub_version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the video\n",
    "video = load_gif('/Volumes/LaCie/videos-you-love-to-take/videoplayback.mp4')\n",
    "print(video.shape)\n",
    "\n",
    "# use only first 100 frames of the video\n",
    "cropped_video = video[:100, :, :, :]\n",
    "\n",
    "# Run the model on the video and output the top 5 predictions\n",
    "outputs = predict_top_k(model, cropped_video)\n",
    "\n",
    "for label, prob in outputs:\n",
    "  print(label, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mapping to convert the output of the model to the original labels\n",
    "with open(\"/Volumes/LaCie/videos-you-love-to-take/kinetics_600_to_labels.json\", 'r') as file:\n",
    "    label_mapping = json.load(file)\n",
    "new_outputs = map_and_sum_labels_and_probs(outputs, label_mapping)\n",
    "for label, prob in new_outputs:\n",
    "    print(label, prob)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
